arrange(desc(MISC))
org_words_conv <- final_count_NER_conv %>%
select(words, ORG) %>%
filter(ORG > 0) %>%
arrange(desc(ORG))
# for reproducible word clouds
set.seed(123)
#showing plots alt vs. normal views
# loc
par(mfrow = c(1, 2))  # Divides the graphic area into 1 row and 2 columns
wordcloud(words = loc_words_alt$words, freq = loc_words_alt$LOC,
min.freq = 10, max.words = 150, random.order = FALSE,
colors = brewer.pal(7, "Paired")[2:7])
wordcloud(words = loc_words_conv$words, freq = loc_words_conv$LOC,
min.freq = 10, max.words = 150, random.order = FALSE,
colors = brewer.pal(7, "Paired")[2:7])
#Persons
wordcloud(words = per_words_alt$words, freq = per_words_alt$PER,
min.freq = 10, max.words = 150, random.order = FALSE,
colors = brewer.pal(7, "Paired")[2:7])
wordcloud(words = per_words_conv$words, freq = per_words_conv$PER,
min.freq = 10, max.words = 150, random.order = FALSE,
colors = brewer.pal(7, "Paired")[2:7])
#Misc
wordcloud(words = misc_words_alt$words, freq = misc_words_alt$MISC,
min.freq = 10, max.words = 150, random.order = FALSE,
colors = brewer.pal(7, "Paired")[2:7])
wordcloud(words = misc_words_conv$words, freq = misc_words_conv$MISC,
min.freq = 10, max.words = 150, random.order = FALSE,
colors = brewer.pal(7, "Paired")[2:7])
#Organisations
wordcloud(words = org_words_alt$words, freq = org_words_alt$ORG,
min.freq = 10, max.words = 150, random.order = FALSE,
colors = brewer.pal(7, "Paired")[2:7])
wordcloud(words = org_words_conv$words, freq = org_words_conv$ORG,
min.freq = 10, max.words = 150, random.order = FALSE,
colors = brewer.pal(7, "Paired")[2:7])
## opinion vs. descriptive ----
### opinion ----
# Extract entities and words from the NER_column for each row
NER_opi <- NER_column %>%
filter(opinion == 1)
prep_count_NER_opi <- NER_opi %>%
mutate(prep_count_NER_df = map(Entities, extract_entity_und_word)) %>%
pull(prep_count_NER_df)
# convert list to df
list_to_df_opi <- do.call(rbind, prep_count_NER_opi)
# Count the words by entity
count_NER_opi <- list_to_df_opi %>%
group_by(entity, words) %>%
summarise(count = n()) %>%
ungroup()
# convert results in new clearer df
final_count_NER_opi <- pivot_wider(count_NER_opi, names_from = entity, values_from = count, values_fill = 0)
# filter data for different entities
loc_words_opi <- final_count_NER_opi %>%
select(words, LOC) %>%
filter(LOC > 0) %>%
arrange(desc(LOC))
per_words_opi <- final_count_NER_opi %>%
select(words, PER) %>%
filter(PER > 0) %>%
arrange(desc(PER))
misc_words_opi <- final_count_NER_opi %>%
select(words, MISC) %>%
filter(MISC > 0) %>%
arrange(desc(MISC))
org_words_opi <- final_count_NER_opi %>%
select(words, ORG) %>%
filter(ORG > 0) %>%
arrange(desc(ORG))
### descriptive ----
NER_desc <- NER_column %>%
filter(opinion == 0)
prep_count_NER_desc <- NER_desc %>%
mutate(prep_count_NER_desc = map(Entities, extract_entity_und_word)) %>%
pull(prep_count_NER_desc)
# convert list to df
list_to_df_desc <- do.call(rbind, prep_count_NER_desc)
# Count the words by entity
count_NER_desc <- list_to_df_desc %>%
group_by(entity, words) %>%
summarise(count = n()) %>%
ungroup()
# convert results in new clearer df
final_count_NER_desc <- pivot_wider(count_NER_desc, names_from = entity, values_from = count, values_fill = 0)
# filter data for different entities
loc_words_desc <- final_count_NER_desc %>%
select(words, LOC) %>%
filter(LOC > 0) %>%
arrange(desc(LOC))
per_words_desc <- final_count_NER_desc %>%
select(words, PER) %>%
filter(PER > 0) %>%
arrange(desc(PER))
misc_words_desc <- final_count_NER_desc %>%
select(words, MISC) %>%
filter(MISC > 0) %>%
arrange(desc(MISC))
org_words_desc <- final_count_NER_desc %>%
select(words, ORG) %>%
filter(ORG > 0) %>%
arrange(desc(ORG))
# for reproducible word clouds
set.seed(123)
#showing plots alt vs. normal views
# loc
par(mfrow = c(1, 2))  # Divides the graphic area into 1 row and 2 columns
wordcloud(words = loc_words_opi$words, freq = loc_words_opi$LOC,
min.freq = 10, max.words = 150, random.order = FALSE,
colors = brewer.pal(7, "Paired")[2:7])
wordcloud(words = loc_words_desc$words, freq = loc_words_desc$LOC,
min.freq = 50, max.words = 150, random.order = FALSE,
colors = brewer.pal(7, "Paired")[2:7])
#Persons
wordcloud(words = per_words_opi$words, freq = per_words_opi$PER,
min.freq = 10, max.words = 150, random.order = FALSE,
colors = brewer.pal(7, "Paired")[2:7])
wordcloud(words = per_words_desc$words, freq = per_words_desc$PER,
min.freq = 50, max.words = 150, random.order = FALSE,
colors = brewer.pal(7, "Paired")[2:7])
#Misc
wordcloud(words = misc_words_opi$words, freq = misc_words_opi$MISC,
min.freq = 10, max.words = 150, random.order = FALSE,
colors = brewer.pal(7, "Paired")[2:7])
wordcloud(words = misc_words_desc$words, freq = misc_words_desc$MISC,
min.freq = 50, max.words = 150, random.order = FALSE,
colors = brewer.pal(7, "Paired")[2:7])
#Organisations
wordcloud(words = org_words_opi$words, freq = org_words_opi$ORG,
min.freq = 10, max.words = 150, random.order = FALSE,
colors = brewer.pal(7, "Paired")[2:7])
wordcloud(words = org_words_desc$words, freq = org_words_desc$ORG,
min.freq = 50, max.words = 150, random.order = FALSE,
colors = brewer.pal(7, "Paired")[2:7])
#just distinct articles
news_categorised_final_all_NER <- news_categorised_final_all_NER %>%
distinct(title, .keep_all = TRUE)
# Definiere die Stopwörter, die ignoriert werden sollen
custom_stopwords <- c("ple", "pel", "nup","\\*","peu","tel","–","lu","pep","lpl","en","ulekl","oll","ep","lo","ent","uuu",">","plek","elue","enek","\\+")
# Convert the text data into a quanteda document
doc <- corpus(news_categorised_final_all_NER$text)
# Pre-processing der Textdaten, einschließlich Entfernung von Stopwörtern
doc_processed <- doc %>%
tokens(remove_punct = TRUE, remove_numbers = TRUE) %>%
tokens_remove(stopwords("german")) %>%
tokens_remove(custom_stopwords)  # Manuelle Entfernung der individuellen Stopwörter
## keyness comparison for conventional news vs alternative news ----
# Erstelle die Document-Feature-Matrix (dfm)
dfm_conv_alt <- dfm(doc_processed, groups = news_categorised_final_all_NER$is_alt_news)
# Trimme die dfm, um leere Dokumente zu entfernen
dfm_conv_alt <- dfm_trim(dfm_conv_alt)
# Überprüfe, ob die dfm mindestens einen nicht-null Wert enthält
if (sum(dfm_conv_alt) == 0) {
stop("Die dfm enthält keine nicht-null Werte. Überprüfe deine Stopwort-Entfernungslogik.")
}
# Perform Keyness-Analyse
keyness_results_conv_alt <- textstat_keyness(dfm_conv_alt)
# plot results
textplot_keyness(keyness_results_conv_alt)
## keyness comparison for opinion news vs despriptive news ----
# Erstelle die Document-Feature-Matrix (dfm)
dfm_conv_opi <- dfm(doc_processed, groups = news_categorised_final_all_NER$opinion)
# Trimme die dfm, um leere Dokumente zu entfernen
dfm_conv_opi <- dfm_trim(dfm_conv_opi)
# Überprüfe, ob die dfm mindestens einen nicht-null Wert enthält
if (sum(dfm_conv_opi) == 0) {
stop("Die dfm enthält keine nicht-null Werte. Überprüfe deine Stopwort-Entfernungslogik.")
}
# Perform Keyness-Analyse
keyness_results_conv_opi <- textstat_keyness(dfm_conv_opi)
# plot results
textplot_keyness(keyness_results_conv_opi)
# Definiere die Stopwörter, die ignoriert werden sollen
custom_stopwords <- c("dts","gru","bri","te","\\''","")
# Convert the text data into a quanteda document
doc <- corpus(news_categorised_final_all_NER$Entities)
# Pre-processing der Textdaten, einschließlich Entfernung von Stopwörtern
doc_processed <- doc %>%
tokens(remove_punct = TRUE, remove_numbers = TRUE) %>%
tokens_remove(custom_stopwords)  # Manuelle Entfernung der individuellen Stopwörter
# Erstelle die Document-Feature-Matrix (dfm)
dfm_conv_alt <- dfm(doc_processed, groups = news_categorised_final_all_NER$is_alt_news)
# Trimme die dfm, um leere Dokumente zu entfernen
dfm_conv_alt <- dfm_trim(dfm_conv_alt)
# Überprüfe, ob die dfm mindestens einen nicht-null Wert enthält
if (sum(dfm_conv_alt) == 0) {
stop("Die dfm enthält keine nicht-null Werte. Überprüfe deine Stopwort-Entfernungslogik.")
}
# Perform Keyness-Analyse
keyness_results_conv_alt <- textstat_keyness(dfm_conv_alt)
# plot results
textplot_keyness(keyness_results_conv_alt)
## keyness comparison for opinion news vs despriptive news ----
# Erstelle die Document-Feature-Matrix (dfm)
dfm_conv_opi <- dfm(doc_processed, groups = news_categorised_final_all_NER$opinion)
# Trimme die dfm, um leere Dokumente zu entfernen
dfm_conv_opi <- dfm_trim(dfm_conv_opi)
# Überprüfe, ob die dfm mindestens einen nicht-null Wert enthält
if (sum(dfm_conv_opi) == 0) {
stop("Die dfm enthält keine nicht-null Werte. Überprüfe deine Stopwort-Entfernungslogik.")
}
# Perform Keyness-Analyse
keyness_results_conv_opi <- textstat_keyness(dfm_conv_opi)
# plot results
textplot_keyness(keyness_results_conv_opi)
# Convert the text data into a quanteda document
dfm_descr_opi <- dfm(news_categorised_final_all_NER$Entities)
# Convert to a dfm object
dfm_descr_opi <- dfm(dfm_descr_opi, groups = news_categorised_final_all_NER$opinion)
# Perform pre-processing of the text data (e.g. tokenization, removal of stop words, etc.)
keyness_results_descr_opi <- textstat_keyness(dfm_descr_opi)
# plot results
textplot_keyness(keyness_results_descr_opi)
library(pacman)
p_load(stringr,
dplyr,
tidyr,
purrr,
readxl,
wordcloud,
quanteda,
quanteda.textstats,
quanteda.textplots,
quanteda.textmodels)
#### only for entities that appear in both sets (entity in conv AND alt) ####
# conv. vs. alt.
# PER
matched_per_comp_alt_conv_both_contained  <- data.frame(inner_join(per_words_conv, per_words_alt, by = c("words" = "words")))
colnames(matched_per_comp_alt_conv_both_contained) <-c("words", "count_conv", "count_alt")
rownames(matched_per_comp_alt_conv_both_contained) <- matched_per_comp_alt_conv_both_contained$words
matched_per_comp_alt_conv_both_contained$words <- NULL
# LOC
matched_loc_comp_alt_conv_both_contained  <- data.frame(inner_join(loc_words_conv, loc_words_alt, by = c("words" = "words")))
colnames(matched_loc_comp_alt_conv_both_contained) <-c("words", "count_conv", "count_alt")
rownames(matched_loc_comp_alt_conv_both_contained) <- matched_loc_comp_alt_conv_both_contained$words
matched_loc_comp_alt_conv_both_contained$words <- NULL
# ORG
matched_org_comp_alt_conv_both_contained  <- data.frame(inner_join(org_words_conv, org_words_alt, by = c("words" = "words")))
colnames(matched_org_comp_alt_conv_both_contained) <-c("words", "count_conv", "count_alt")
rownames(matched_org_comp_alt_conv_both_contained) <- matched_org_comp_alt_conv_both_contained$words
matched_org_comp_alt_conv_both_contained$words <- NULL
# MISC
matched_misc_comp_alt_conv_both_contained  <- data.frame(inner_join(misc_words_conv, misc_words_alt, by = c("words" = "words")))
colnames(matched_misc_comp_alt_conv_both_contained) <-c("words", "count_conv", "count_alt")
rownames(matched_misc_comp_alt_conv_both_contained) <- matched_misc_comp_alt_conv_both_contained$words
matched_misc_comp_alt_conv_both_contained$words <- NULL
# construct word clouds conv. vs. alt.
comparison.cloud(matched_per_comp_alt_conv_both_contained, max.words = 35, random.order= F, title.size = 1.5)
comparison.cloud(matched_loc_comp_alt_conv_both_contained, max.words = 30, random.order= F, title.size = 1.5)
comparison.cloud(matched_org_comp_alt_conv_both_contained, max.words = 30, random.order= F, title.size = 1.5)
comparison.cloud(matched_misc_comp_alt_conv_both_contained, max.words = 30, random.order= F, title.size = 1.5)
# opi. vs. normal
# PER
matched_per_comp_opi_desc_both_contained  <- data.frame(inner_join(per_words_desc, per_words_opi, by = c("words" = "words")))
colnames(matched_per_comp_opi_desc_both_contained) <-c("words", "count_desc", "count_opi")
rownames(matched_per_comp_opi_desc_both_contained) <- matched_per_comp_opi_desc_both_contained$words
matched_per_comp_opi_desc_both_contained$words <- NULL
# LOC
matched_loc_comp_opi_desc_both_contained  <- data.frame(inner_join(loc_words_desc, loc_words_opi, by = c("words" = "words")))
colnames(matched_loc_comp_opi_desc_both_contained) <-c("words", "count_desc", "count_opi")
rownames(matched_loc_comp_opi_desc_both_contained) <- matched_loc_comp_opi_desc_both_contained$words
matched_loc_comp_opi_desc_both_contained$words <- NULL
# ORG
matched_org_comp_opi_desc_both_contained  <- data.frame(inner_join(org_words_desc, org_words_opi, by = c("words" = "words")))
colnames(matched_org_comp_opi_desc_both_contained) <-c("words", "count_desc", "count_opi")
rownames(matched_org_comp_opi_desc_both_contained) <- matched_org_comp_opi_desc_both_contained$words
matched_org_comp_opi_desc_both_contained$words <- NULL
# MISC
matched_misc_comp_opi_desc_both_contained  <- data.frame(inner_join(misc_words_desc, misc_words_opi, by = c("words" = "words")))
colnames(matched_misc_comp_opi_desc_both_contained) <-c("words", "count_desc", "count_opi")
rownames(matched_misc_comp_opi_desc_both_contained) <- matched_misc_comp_opi_desc_both_contained$words
matched_misc_comp_opi_desc_both_contained$words <- NULL
# construct word clouds desc. vs. opi.
comparison.cloud(matched_per_comp_opi_desc_both_contained, max.words = 40, random.order= F,  title.size = 1)
comparison.cloud(matched_loc_comp_opi_desc_both_contained, max.words = 40, random.order= F,  title.size = 1)
comparison.cloud(matched_org_comp_opi_desc_both_contained, max.words = 40, random.order= F,  title.size = 1)
comparison.cloud(matched_misc_comp_opi_desc_both_contained, max.words = 40, random.order= F, title.size = 1)
#### all entities (in conv OR alt) ####
# conv. vs. alt.
# PER
matched_per_comp_alt_conv_all_contained  <- data.frame(full_join(per_words_conv, per_words_alt, by = c("words" = "words")))
colnames(matched_per_comp_alt_conv_all_contained) <-c("words", "count_conv", "count_alt")
rownames(matched_per_comp_alt_conv_all_contained) <- matched_per_comp_alt_conv_all_contained$words
matched_per_comp_alt_conv_all_contained$words <- NULL
matched_per_comp_alt_conv_all_contained[is.na(matched_per_comp_alt_conv_all_contained)] <- 0
# LOC
matched_loc_comp_alt_conv_all_contained  <- data.frame(full_join(loc_words_conv, loc_words_alt, by = c("words" = "words")))
colnames(matched_loc_comp_alt_conv_all_contained) <-c("words", "count_conv", "count_alt")
rownames(matched_loc_comp_alt_conv_all_contained) <- matched_loc_comp_alt_conv_all_contained$words
matched_loc_comp_alt_conv_all_contained$words <- NULL
matched_loc_comp_alt_conv_all_contained[is.na(matched_loc_comp_alt_conv_all_contained)] <- 0
# ORG
matched_org_comp_alt_conv_all_contained  <- data.frame(full_join(org_words_conv, org_words_alt, by = c("words" = "words")))
colnames(matched_org_comp_alt_conv_all_contained) <-c("words", "count_conv", "count_alt")
rownames(matched_org_comp_alt_conv_all_contained) <- matched_org_comp_alt_conv_all_contained$words
matched_org_comp_alt_conv_all_contained$words <- NULL
matched_org_comp_alt_conv_all_contained[is.na(matched_org_comp_alt_conv_all_contained)] <- 0
# MISC
matched_misc_comp_alt_conv_all_contained  <- data.frame(full_join(misc_words_conv, misc_words_alt, by = c("words" = "words")))
colnames(matched_misc_comp_alt_conv_all_contained) <-c("words", "count_conv", "count_alt")
rownames(matched_misc_comp_alt_conv_all_contained) <- matched_misc_comp_alt_conv_all_contained$words
matched_misc_comp_alt_conv_all_contained$words <- NULL
matched_misc_comp_alt_conv_all_contained[is.na(matched_misc_comp_alt_conv_all_contained)] <- 0
# construct word clouds conv. vs. alt.
comparison.cloud(matched_per_comp_alt_conv_all_contained, max.words = 40, random.order= F, title.size = 1.5)
comparison.cloud(matched_loc_comp_alt_conv_all_contained, max.words = 40, random.order= F, title.size = 1.5)
comparison.cloud(matched_org_comp_alt_conv_all_contained, max.words = 40, random.order= F, title.size = 1.5)
comparison.cloud(matched_misc_comp_alt_conv_all_contained, max.words = 40, random.order= F, title.size = 1.5)
# opi. vs. normal
# PER
matched_per_comp_opi_desc_all_contained  <- data.frame(full_join(per_words_desc, per_words_opi, by = c("words" = "words")))
colnames(matched_per_comp_opi_desc_all_contained) <-c("words", "count_desc", "count_opi")
rownames(matched_per_comp_opi_desc_all_contained) <- matched_per_comp_opi_desc_all_contained$words
matched_per_comp_opi_desc_all_contained$words <- NULL
matched_per_comp_opi_desc_all_contained[is.na(matched_per_comp_opi_desc_all_contained)] <- 0
# LOC
matched_loc_comp_opi_desc_all_contained  <- data.frame(full_join(loc_words_desc, loc_words_opi, by = c("words" = "words")))
colnames(matched_loc_comp_opi_desc_all_contained) <-c("words", "count_desc", "count_opi")
rownames(matched_loc_comp_opi_desc_all_contained) <- matched_loc_comp_opi_desc_all_contained$words
matched_loc_comp_opi_desc_all_contained$words <- NULL
matched_per_comp_opi_desc_all_contained[is.na(matched_per_comp_opi_desc_all_contained)] <- 0
# ORG
matched_org_comp_opi_desc_all_contained  <- data.frame(full_join(org_words_desc, org_words_opi, by = c("words" = "words")))
colnames(matched_org_comp_opi_desc_all_contained) <-c("words", "count_desc", "count_opi")
rownames(matched_org_comp_opi_desc_all_contained) <- matched_org_comp_opi_desc_all_contained$words
matched_org_comp_opi_desc_all_contained$words <- NULL
matched_per_comp_opi_desc_all_contained[is.na(matched_per_comp_opi_desc_all_contained)] <- 0
# MISC
matched_misc_comp_opi_desc_all_contained  <- data.frame(full_join(misc_words_desc, misc_words_opi, by = c("words" = "words")))
colnames(matched_misc_comp_opi_desc_all_contained) <-c("words", "count_desc", "count_opi")
rownames(matched_misc_comp_opi_desc_all_contained) <- matched_misc_comp_opi_desc_all_contained$words
matched_misc_comp_opi_desc_all_contained$words <- NULL
matched_per_comp_opi_desc_all_contained[is.na(matched_per_comp_opi_desc_all_contained)] <- 0
# construct word clouds desc. vs. opi.
comparison.cloud(matched_per_comp_opi_desc_all_contained, max.words = 40, random.order= F, title.size = 1.5)
comparison.cloud(matched_loc_comp_opi_desc_all_contained, max.words = 40, random.order= F, title.size = 1.5)
#### only for entities that appear in both sets (entity in conv AND alt) ####
# conv. vs. alt.
# PER
list_to_df_alt_PER <- list_to_df_alt %>% filter(entity == "PER") %>% mutate(set = "Alternative news")
list_to_df_conv_PER <- list_to_df_conv %>% filter(entity == "PER") %>% mutate(set = "Conventional news")
# LOC
list_to_df_alt_LOC <- list_to_df_alt %>% filter(entity == "LOC") %>% mutate(set = "Alternative news")
list_to_df_conv_LOC <- list_to_df_conv %>% filter(entity == "LOC") %>% mutate(set = "Conventional news")
# ORG
list_to_df_alt_ORG <- list_to_df_alt %>% filter(entity == "ORG") %>% mutate(set = "Alternative news")
list_to_df_conv_ORG <- list_to_df_conv %>% filter(entity == "ORG") %>% mutate(set = "Conventional news")
# MISC
list_to_df_alt_MISC <- list_to_df_alt %>% filter(entity == "MISC") %>% mutate(set = "Alternative news")
list_to_df_conv_MISC <- list_to_df_conv %>% filter(entity == "MISC") %>% mutate(set = "Conventional news")
merged_alt_conv_PER <- bind_rows(list_to_df_alt_PER, list_to_df_conv_PER)
merged_alt_conv_LOC <- bind_rows(list_to_df_alt_LOC, list_to_df_conv_LOC)
merged_alt_conv_ORG <- bind_rows(list_to_df_alt_ORG, list_to_df_conv_ORG)
merged_alt_conv_MISC <- bind_rows(list_to_df_alt_MISC, list_to_df_conv_MISC)
merged2_alt_conv_PER <- merged_alt_conv_PER %>% group_by(words) %>% filter(all(c("Alternative news", "Conventional news") %in% set)) %>% ungroup()
merged2_alt_conv_LOC <- merged_alt_conv_LOC %>% group_by(words) %>% filter(all(c("Alternative news", "Conventional news") %in% set)) %>% ungroup()
merged2_alt_conv_ORG <- merged_alt_conv_ORG %>% group_by(words) %>% filter(all(c("Alternative news", "Conventional news") %in% set)) %>% ungroup()
merged2_alt_conv_MISC <- merged_alt_conv_MISC %>% group_by(words) %>% filter(all(c("Alternative news", "Conventional news") %in% set)) %>% ungroup()
# construct a corpus-object from the datasets
corpus_alt_conv_PER <- corpus(merged2_alt_conv_PER$words, docvars = merged2_alt_conv_PER$set)
corpus_alt_conv_LOC <- corpus(merged2_alt_conv_LOC$words, docvars = merged2_alt_conv_LOC$set)
corpus_alt_conv_ORG <- corpus(merged2_alt_conv_ORG$words, docvars = merged2_alt_conv_ORG$set)
corpus_alt_conv_MISC <- corpus(merged2_alt_conv_MISC$words, docvars = merged2_alt_conv_MISC$set)
# construct a Document-Term-Matrix (dfm) from the corpus
dfm_alt_conv_PER <- tokens(corpus_alt_conv_PER, what = "sentence", include_docvars = TRUE) %>%
dfm(tolower = FALSE) %>%
dfm_group(groups = docvars)
dfm_alt_conv_LOC <- tokens(corpus_alt_conv_LOC, what = "sentence", include_docvars = TRUE) %>%
dfm(tolower = FALSE) %>%
dfm_group(groups = docvars)
dfm_alt_conv_ORG <- tokens(corpus_alt_conv_ORG, what = "sentence", include_docvars = TRUE) %>%
dfm(tolower = FALSE) %>%
dfm_group(groups = docvars)
dfm_alt_conv_MISC <- tokens(corpus_alt_conv_MISC, what = "sentence", include_docvars = TRUE) %>%
dfm(tolower = FALSE) %>%
dfm_group(groups = docvars)
textplot_wordcloud(dfm_alt_conv_PER,
max_words = 30,
#min_count = 50, # !!! filters data and calculates rel. frequency based on the filtered data
comparison = TRUE,
color = c('red', 'blue'),
min_size = 1,
max_size = 4,
random_order = F)
textplot_wordcloud(dfm_alt_conv_LOC,
max_words = 30,
#min_count = 50, # !!! filters data and calculates rel. frequency based on the filtered data
comparison = TRUE,
color = c('red', 'blue'),
min_size = 1,
max_size = 4,
random_order = F)
textplot_wordcloud(dfm_alt_conv_ORG,
max_words = 30,
#min_count = 50, # !!! filters data and calculates rel. frequency based on the filtered data
comparison = TRUE,
color = c('red', 'blue'),
min_size = 1,
max_size = 4,
random_order = F)
textplot_wordcloud(dfm_alt_conv_MISC,
max_words = 30,
#min_count = 50, # !!! filters data and calculates rel. frequency based on the filtered data
comparison = TRUE,
color = c('red', 'blue'),
min_size = 1,
max_size = 4,
random_order = F)
# opi. vs. desc.
# PER
list_to_df_opi_PER <- list_to_df_opi %>% filter(entity == "PER") %>% mutate(set = "Opinion news")
list_to_df_desc_PER <- list_to_df_desc %>% filter(entity == "PER") %>% mutate(set = "Descriptive news")
# LOC
list_to_df_opi_LOC <- list_to_df_opi %>% filter(entity == "LOC") %>% mutate(set = "Opinion news")
list_to_df_desc_LOC <- list_to_df_desc %>% filter(entity == "LOC") %>% mutate(set = "Descriptive news")
# ORG
list_to_df_opi_ORG <- list_to_df_opi %>% filter(entity == "ORG") %>% mutate(set = "Opinion news")
list_to_df_desc_ORG <- list_to_df_desc %>% filter(entity == "ORG") %>% mutate(set = "Descriptive news")
# MISC
list_to_df_opi_MISC <- list_to_df_opi %>% filter(entity == "MISC") %>% mutate(set = "Opinion news")
list_to_df_desc_MISC <- list_to_df_desc %>% filter(entity == "MISC") %>% mutate(set = "Descriptive news")
merged_opi_desc_PER <- bind_rows(list_to_df_opi_PER, list_to_df_desc_PER)
merged_opi_desc_LOC <- bind_rows(list_to_df_opi_LOC, list_to_df_desc_LOC)
merged_opi_desc_ORG <- bind_rows(list_to_df_opi_ORG, list_to_df_desc_ORG)
merged_opi_desc_MISC <- bind_rows(list_to_df_opi_MISC, list_to_df_desc_MISC)
merged2_opi_desc_PER <- merged_opi_desc_PER %>% group_by(words) %>% filter(all(c("Opinion news", "Descriptive news") %in% set)) %>% ungroup()
merged2_opi_desc_LOC <- merged_opi_desc_LOC %>% group_by(words) %>% filter(all(c("Opinion news", "Descriptive news") %in% set)) %>% ungroup()
merged2_opi_desc_ORG <- merged_opi_desc_ORG %>% group_by(words) %>% filter(all(c("Opinion news", "Descriptive news") %in% set)) %>% ungroup()
merged2_opi_desc_MISC <- merged_opi_desc_MISC %>% group_by(words) %>% filter(all(c("Opinion news", "Descriptive news") %in% set)) %>% ungroup()
# construct a corpus-object from the datasets
corpus_opi_desc_PER <- corpus(merged2_opi_desc_PER$words, docvars = merged2_opi_desc_PER$set)
corpus_opi_desc_LOC <- corpus(merged2_opi_desc_LOC$words, docvars = merged2_opi_desc_LOC$set)
corpus_opi_desc_ORG <- corpus(merged2_opi_desc_ORG$words, docvars = merged2_opi_desc_ORG$set)
corpus_opi_desc_MISC <- corpus(merged2_opi_desc_MISC$words, docvars = merged2_opi_desc_MISC$set)
# construct a Document-Term-Matrix (dfm) from the corpus
dfm_opi_desc_PER <- tokens(corpus_opi_desc_PER, what = "sentence", include_docvars = TRUE) %>%
dfm(tolower = FALSE) %>%
dfm_group(groups = docvars)
dfm_opi_desc_LOC <- tokens(corpus_opi_desc_LOC, what = "sentence", include_docvars = TRUE) %>%
dfm(tolower = FALSE) %>%
dfm_group(groups = docvars)
dfm_opi_desc_ORG <- tokens(corpus_opi_desc_ORG, what = "sentence", include_docvars = TRUE) %>%
dfm(tolower = FALSE) %>%
dfm_group(groups = docvars)
dfm_opi_desc_MISC <- tokens(corpus_opi_desc_MISC, what = "sentence", include_docvars = TRUE) %>%
dfm(tolower = FALSE) %>%
dfm_group(groups = docvars)
textplot_wordcloud(dfm_opi_desc_PER[c(2, 1), ], # change order, since dfm object uses alphabetical order
max_words = 30,
#min_count = 50, # !!! filters data and calculates rel. frequency based on the filtered data
comparison = TRUE,
color = c('red', 'blue'),
min_size = 1,
max_size = 4,
random_order = F)
textplot_wordcloud(dfm_opi_desc_LOC[c(2, 1), ], # change order, since dfm object uses alphabetical order
max_words = 30,
#min_count = 50, # !!! filters data and calculates rel. frequency based on the filtered data
comparison = TRUE,
color = c('red', 'blue'),
min_size = 1,
max_size = 4,
random_order = F)
textplot_wordcloud(dfm_opi_desc_ORG[c(2, 1), ], # change order, since dfm object uses alphabetical order
max_words = 30,
#min_count = 50, # !!! filters data and calculates rel. frequency based on the filtered data
comparison = TRUE,
color = c('red', 'blue'),
min_size = 1,
max_size = 4,
random_order = F)
textplot_wordcloud(dfm_opi_desc_MISC[c(2, 1), ], # change order, since dfm object uses alphabetical order
max_words = 30,
#min_count = 50, # !!! filters data and calculates rel. frequency based on the filtered data
comparison = TRUE,
color = c('red', 'blue'),
min_size = 1,
max_size = 4,
random_order = F)
textplot_wordcloud(dfm_opi_desc_PER[c(2, 1), ], # change order, since dfm object uses alphabetical order
max_words = 30,
#min_count = 50, # !!! filters data and calculates rel. frequency based on the filtered data
comparison = TRUE,
color = c('red', 'blue'),
min_size = 1,
max_size = 4,
random_order = F)
textplot_wordcloud(dfm_opi_desc_LOC[c(2, 1), ], # change order, since dfm object uses alphabetical order
max_words = 30,
#min_count = 50, # !!! filters data and calculates rel. frequency based on the filtered data
comparison = TRUE,
color = c('red', 'blue'),
min_size = 1,
max_size = 4,
random_order = F)
textplot_wordcloud(dfm_opi_desc_ORG[c(2, 1), ], # change order, since dfm object uses alphabetical order
max_words = 30,
#min_count = 50, # !!! filters data and calculates rel. frequency based on the filtered data
comparison = TRUE,
color = c('red', 'blue'),
min_size = 1,
max_size = 4,
random_order = F)
textplot_wordcloud(dfm_opi_desc_MISC[c(2, 1), ], # change order, since dfm object uses alphabetical order
max_words = 30,
#min_count = 50, # !!! filters data and calculates rel. frequency based on the filtered data
comparison = TRUE,
color = c('red', 'blue'),
min_size = 1,
max_size = 4,
random_order = F)
